---
title: "DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models"
collection: publications
permalink: /publication/2025_ICDM
# excerpt: "Transfer learning has become a prevailing machine learning technique thanks to its superiority in learning knowledge from limited training data for prediction. In the existing works, collection and collaboration are two major approaches to realize the improvement of transfer learning performance. Even though the effectiveness of these approaches has been validated in extensive experiments, there lacks the support of theoretical analysis. Consequently, how to enhance transfer learning effectively is an open problem. In light of this, in this paper, we thoroughly and deeply study the methods of improving transfer learning performance in order to provide the guidelines for applying transfer learning in real applications. Through our proof process, critical conclusions are drawn to help learn the motivation of implementing collection and collaboration, the performance gap between collection and collaboration, and the impacts of data sharing strategies on transfer learning in collaboration. These conclusions can further build a theoretical foundation for future research on transfer learning."
date: 2025-08-25
# venue: "October 14"
# paperurl: "http://honghuixuhenry.github.io/files/TCS.pdf"
# citation: "Xu H, Li W, Cai Z. Analysis on methods to effectively improve transfer learning performance[J]. Theoretical Computer Science, 2023, 940: 90-107."
---

**[IoTJ]** **H. Xu**, S. Shrestha, W. Chen, Z. Li and Z. Cai, DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models [C]. _IEEE International Conference on Data Mining (ICDM)_, 2025. (**Acceptance Ratio: 13.5\%**) [Download paper here](http://honghuixuhenry.github.io/files/ICDM3.pdf)

As on-device large language model (LLM) systems become increasingly prevalent, federated fine-tuning enables advanced language understanding and generation directly on edge devices; however, it also involves processing sensitive, user-specific data, raising significant privacy concerns within the federated learning framework. To address these challenges, we propose DP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates LoRA-based adaptation with differential privacy in a communication-efficient setting. Each client locally clips and perturbs its LoRA matrices using Gaussian noise to satisfy \epsilon-differential privacy. We further provide a theoretical analysis demonstrating the unbiased nature of the updates and deriving bounds on the variance introduced by noise, offering practical guidance for privacy-budget calibration. Experimental results across mainstream benchmarks show that DP-FedLoRA delivers competitive performance while offering strong privacy guarantees, paving the way for scalable and privacy-preserving LLM deployment in on-device environments.